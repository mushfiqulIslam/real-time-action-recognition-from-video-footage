{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "designing-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from tools.settings import *\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tools.train_val_test_spliter import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "configured-footage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the ginen dataset into Train Test=0.4 Validation=0.1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# To split dataset if already splits folder already exits no need to run it\n",
    "split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "static-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd. read_csv(os.path.join(dataset_path, \"train.csv\"))\n",
    "test = pd. read_csv(os.path.join(dataset_path, \"test.csv\"))\n",
    "val = pd. read_csv(os.path.join(dataset_path, \"val.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rising-concrete",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_url</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>punch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>kick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>kick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>punch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Video_url action\n",
       "0  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "1  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...  punch\n",
       "2  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   kick\n",
       "3  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   kick\n",
       "4  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...  punch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stainless-personal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_url</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>punch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>kick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Video_url action\n",
       "0  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "1  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "2  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...  punch\n",
       "3  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   kick\n",
       "4  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pharmaceutical-honduras",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_url</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>punch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>kick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>kick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Video_url action\n",
       "0  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...  punch\n",
       "1  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   kick\n",
       "2  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "3  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   kick\n",
       "4  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "twelve-independence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 2)\n",
      "(111, 2)\n",
      "(27, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "forced-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_frame(data, folder_name):\n",
    "    '''\n",
    "    Generated filenames format dataset_path/folder_name/video_name_frame{number}_action.jpg\n",
    "    '''\n",
    "    directory = os.path.join(dataset_path, folder_name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        video_file = data['Video_url'][i]\n",
    "        action = data['action'][i]\n",
    "        video_name_list = video_file.split('/')[-1].split('.')\n",
    "        video_name_list = video_name_list[:-1]\n",
    "        video_name = \"\"\n",
    "        for n in video_name_list:\n",
    "            video_name += n\n",
    "        # capturing the video from the given path\n",
    "        capture = cv2.VideoCapture(video_file) \n",
    "        #frame rate\n",
    "        frame_rate = capture.get(5)\n",
    "        count = 0\n",
    "        while(capture.isOpened()):\n",
    "            #current frame number\n",
    "            frame_id = capture.get(1) \n",
    "            read_correctly, frame = capture.read()\n",
    "            if not read_correctly:\n",
    "                break\n",
    "            if (frame_id % math.floor(frame_rate) == 0):\n",
    "                # storing the frames in a new folder named train_1\n",
    "                filename = directory + \"/\" + video_name + \"_frame{}_\".format(count) + action +\".jpg\"\n",
    "                count += 1\n",
    "                cv2.imwrite(filename, frame)\n",
    "        capture.release()\n",
    "    print(\"Successfully Converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "criminal-wound",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:50<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Converted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_to_frame(train, train_frames_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "veterinary-argentina",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:09<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Converted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_to_frame(val, val_frames_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compact-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paths_csv(directory, file_name):\n",
    "    images = os.listdir(directory)\n",
    "    images_path_list = []\n",
    "    images_action_list = [] \n",
    "    for image in images:\n",
    "        images_path_list.append(directory + image)\n",
    "        images_action_list.append(image.split('.')[0].split('_')[-1])\n",
    "    df = pd.DataFrame()\n",
    "    df['image'] = images_path_list\n",
    "    df['action'] = images_action_list\n",
    "    print(os.path.join(dataset_path, file_name+'.csv'))\n",
    "    df.to_csv(os.path.join(dataset_path, file_name+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "electronic-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-time-action-recognition-from-video-footage/dataset/train_frames.csv\n"
     ]
    }
   ],
   "source": [
    "create_paths_csv(train_frames_path, train_frames_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "animated-prototype",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-time-action-recognition-from-video-footage/dataset/val_frames.csv\n"
     ]
    }
   ],
   "source": [
    "create_paths_csv(val_frames_path, val_frames_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adapted-reservoir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>punch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image action\n",
       "0  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...  punch\n",
       "1  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "2  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "3  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "4  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image = pd.read_csv(os.path.join(dataset_path, 'train_frames.csv'))\n",
    "train_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "refined-hybrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "described-diameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>kick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image action\n",
       "0  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "1  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "2  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   kick\n",
       "3  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap\n",
       "4  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...   slap"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image = pd.read_csv(os.path.join(dataset_path, 'val_frames.csv'))\n",
    "val_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "warming-bearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 2)\n"
     ]
    }
   ],
   "source": [
    "print(val_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "regular-guess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['punch', 'slap', 'kick']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_values = list(train_image['action'].unique())\n",
    "action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "introductory-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_columns(df):\n",
    "    for value in action_values:\n",
    "        df[value] = np.where(df['action'].str.contains(value), 1, 0)\n",
    "    df.drop('action', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "falling-initial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>punch</th>\n",
       "      <th>slap</th>\n",
       "      <th>kick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  punch  slap  kick\n",
       "0  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      1     0     0\n",
       "1  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      0     1     0\n",
       "2  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      0     1     0\n",
       "3  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      0     1     0\n",
       "4  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      0     1     0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_class_columns(train_image)\n",
    "train_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "structured-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>punch</th>\n",
       "      <th>slap</th>\n",
       "      <th>kick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  punch  slap  kick\n",
       "0  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      0     1     0\n",
       "1  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      0     1     0\n",
       "2  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      0     0     1\n",
       "3  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      0     1     0\n",
       "4  /home/mushfiqul/Mushfiqul/CSE/Thesis2.0/real-t...      0     1     0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_class_columns(val_image)\n",
    "val_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stopped-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_array_and_split(image_data):\n",
    "    image_value = []\n",
    "    for i in tqdm(range(image_data.shape[0])):\n",
    "        img = image.load_img(image_data['image'][i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        # normalizing the pixel value\n",
    "        img = img / 255\n",
    "        image_value.append(img)\n",
    "\n",
    "    X = np.array(image_value)\n",
    "    y = image_data\n",
    "    y.drop('image', axis='columns', inplace=True)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "everyday-skiing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 620/620 [00:11<00:00, 53.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = convert_to_array_and_split(train_image)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "communist-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:01<00:00, 59.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = convert_to_array_and_split(val_image)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cutting-stylus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>punch</th>\n",
       "      <th>slap</th>\n",
       "      <th>kick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   punch  slap  kick\n",
       "0      1     0     0\n",
       "1      0     1     0\n",
       "2      0     1     0\n",
       "3      0     1     0\n",
       "4      0     1     0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unauthorized-machine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  action\n",
       "0   slap\n",
       "1   slap\n",
       "2   kick\n",
       "3   slap\n",
       "4   slap"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "satellite-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This model was trained on a dataset that has 1,000 classes. \n",
    "include_top = False will remove the last layer of this model so that we can tune it as per our need.\n",
    "'''\n",
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unable-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 7, 7, 512)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "studied-machinery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 7, 7, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = base_model.predict(X_val)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mexican-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(620, 7*7*512)\n",
    "X_val = X_val.reshape(115, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "retained-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 25088)\n",
      "(115, 25088)\n"
     ]
    }
   ],
   "source": [
    "# normalizing the pixel values\n",
    "max_pixel = X_train.max()\n",
    "X_train = X_train / max_pixel\n",
    "X_val = X_val / max_pixel\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "supreme-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input shape will be 25,088\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cosmetic-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_weight = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "occupied-business",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8934590b741e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcp_weight\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/mushfiqul/anaconda3/envs/action-recognition/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[mcp_weight], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "loving-lunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 26,380,547\n",
      "Trainable params: 26,380,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weight.hdf5\")\n",
    "# model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "basic-glass",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [04:47<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as s\n",
    "predict = []\n",
    "actual = []\n",
    "if not os.path.exists(test_frames_path):\n",
    "    os.makedirs(test_frames_path)\n",
    "\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    video_file = test['Video_url'][i]\n",
    "    action = test['action'][i]\n",
    "    video_name_list = video_file.split('/')[-1].split('.')\n",
    "    video_name_list = video_name_list[:-1]\n",
    "    video_name = \"\"\n",
    "    for n in video_name_list:\n",
    "        video_name += n\n",
    "    # capturing the video from the given path\n",
    "    capture = cv2.VideoCapture(video_file) \n",
    "    #frame rate\n",
    "    frame_rate = capture.get(5)\n",
    "    count = 0\n",
    "    files = glob(test_frames_path + '/*')\n",
    "    #removing all files from folder\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while(capture.isOpened()):\n",
    "        #current frame number\n",
    "        frame_id = capture.get(1) \n",
    "        read_correctly, frame = capture.read()\n",
    "        if not read_correctly:\n",
    "            break\n",
    "        if (frame_id % math.floor(frame_rate) == 0):\n",
    "            # storing the frames in a new folder named train_1\n",
    "            filename = test_frames_path + \"/\" + video_name + \"_frame{}_\".format(count) + action +\".jpg\"\n",
    "            count += 1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    capture.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(test_frames_path + '/*.jpg')\n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255\n",
    "        prediction_images.append(img)\n",
    "        \n",
    "    # converting all the frames for a test video into numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "    # extracting features using pre-trained model\n",
    "    prediction_images = base_model.predict(prediction_images)\n",
    "    # converting features in one dimensional array\n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "    # predicting tags for each array\n",
    "    prediction = np.argmax(model.predict(prediction_images), axis=-1)\n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(y_train.columns.values[s.mode(prediction)[0][0]])\n",
    "    # appending the actual tag of the video\n",
    "    actual.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "improving-catering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'punch'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.columns.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "third-baseball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.7927927927928"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "contained-straight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punch slap\n",
      "slap slap\n",
      "kick punch\n",
      "kick kick\n",
      "slap slap\n",
      "slap slap\n",
      "slap slap\n",
      "kick kick\n",
      "punch punch\n",
      "slap slap\n",
      "slap slap\n",
      "slap slap\n",
      "punch punch\n",
      "slap slap\n",
      "slap slap\n",
      "kick kick\n",
      "kick kick\n",
      "slap slap\n",
      "punch punch\n",
      "punch punch\n",
      "slap slap\n",
      "punch slap\n",
      "punch punch\n",
      "slap slap\n",
      "slap slap\n",
      "kick kick\n",
      "slap slap\n",
      "slap slap\n",
      "punch punch\n",
      "kick kick\n",
      "slap slap\n",
      "punch punch\n",
      "kick kick\n",
      "slap slap\n",
      "punch punch\n",
      "slap slap\n",
      "punch punch\n",
      "slap slap\n",
      "slap slap\n",
      "punch punch\n",
      "slap slap\n",
      "punch punch\n",
      "punch punch\n",
      "kick kick\n",
      "punch punch\n",
      "kick kick\n",
      "kick kick\n",
      "punch punch\n",
      "punch punch\n",
      "kick kick\n",
      "punch punch\n",
      "slap slap\n",
      "slap slap\n",
      "slap slap\n",
      "slap slap\n",
      "slap slap\n",
      "punch punch\n",
      "slap slap\n",
      "slap punch\n",
      "punch punch\n",
      "punch punch\n",
      "kick kick\n",
      "kick punch\n",
      "punch punch\n",
      "punch slap\n",
      "slap slap\n",
      "slap slap\n",
      "slap slap\n",
      "punch punch\n",
      "kick kick\n",
      "punch punch\n",
      "slap slap\n",
      "punch punch\n",
      "slap slap\n",
      "kick kick\n",
      "kick kick\n",
      "punch kick\n",
      "punch punch\n",
      "punch punch\n",
      "slap slap\n",
      "kick kick\n",
      "kick kick\n",
      "kick kick\n",
      "kick kick\n",
      "kick kick\n",
      "kick kick\n",
      "slap slap\n",
      "slap slap\n",
      "kick kick\n",
      "kick kick\n",
      "slap slap\n",
      "slap slap\n",
      "slap slap\n",
      "punch punch\n",
      "slap slap\n",
      "kick kick\n",
      "punch punch\n",
      "slap slap\n",
      "slap slap\n",
      "punch punch\n",
      "slap slap\n",
      "punch punch\n",
      "slap slap\n",
      "slap slap\n",
      "kick kick\n",
      "punch punch\n",
      "punch punch\n",
      "slap slap\n",
      "punch punch\n",
      "slap kick\n",
      "kick kick\n"
     ]
    }
   ],
   "source": [
    "# for i in range(0, len(predict)):\n",
    "#     print(predict[i] + \" \" + actual[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-playing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
